{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_feed(filenames, batch_size):\n",
    "    file_q = tf.train.string_input_producer(filenames)\n",
    "    reader = tf.TextLineReader()\n",
    "    k, v = reader.read(file_q)\n",
    "\n",
    "    eng, jp = tf.decode_csv(v, record_defaults=[[\"\"], [\"\"]], field_delim=\"\\t\")\n",
    "    eng = tf.string_split([eng], delimiter=\" \").values\n",
    "    eng = tf.string_to_number(eng, tf.int32)\n",
    "    jp = tf.string_split([jp], delimiter=\" \").values\n",
    "    jp = tf.string_to_number(jp, tf.int32)\n",
    "    seq_len = tf.tuple([eng, jp])\n",
    "\n",
    "    def py_which_bucket(eng, jp):\n",
    "        if len(eng) <= 51 and len(jp) <= 52:\n",
    "            return np.int32(0)\n",
    "        elif len(eng) <= 101 and len(jp) <= 102:\n",
    "            return np.int32(1)\n",
    "        return np.int32(2)\n",
    "\n",
    "    which_bucket = tf.py_func(py_which_bucket, seq_len, tf.int32)\n",
    "    capacity = 10000 + 8 * batch_size\n",
    "    _, (eng_batch, jp_batch) = tf.contrib.training.bucket([eng, jp], which_bucket, batch_size=batch_size, num_buckets=5, num_threads=8, dynamic_pad=True, capacity=capacity)\n",
    "    return eng_batch, jp_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size = 512\n",
    "n_hidden = 512\n",
    "en_vocab_size = 131 + 4\n",
    "jp_vocab_size = 3202 + 4\n",
    "n_layers = 4\n",
    "n_attn_heads = 8\n",
    "dropout_keep_prob = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_embedding(X, Y, reuse=False):\n",
    "    with tf.variable_scope(\"embedding\", reuse=reuse), tf.device(\"/cpu:0\"):\n",
    "        en_emb = tf.get_variable(\"en_emb\", \n",
    "                                [en_vocab_size, emb_size], \n",
    "                                dtype=tf.float32,\n",
    "                                initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "\n",
    "        jp_emb = tf.get_variable(\"jp_emb\", \n",
    "                                [jp_vocab_size, emb_size], \n",
    "                                dtype=tf.float32,\n",
    "                                initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "\n",
    "        P_in = tf.get_variable(\"P_in\", \n",
    "                            [401, emb_size], \n",
    "                            dtype=tf.float32,\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "        P_out = tf.get_variable(\"P_out\", \n",
    "                            [402, emb_size], \n",
    "                            dtype=tf.float32,\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "\n",
    "        X_emb = tf.nn.embedding_lookup(en_emb, X) + P_in[:tf.shape(X)[1], :]\n",
    "        Y_emb = tf.nn.embedding_lookup(jp_emb, Y) + P_out[:tf.shape(Y)[1], :]\n",
    "        return X_emb, Y_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder_block(inp, n_hidden, filter_size):\n",
    "    inp = tf.expand_dims(inp, 2)\n",
    "    inp = tf.pad(inp, [[0, 0], [(filter_size[0]-1)//2, (filter_size[0]-1)//2], [0, 0], [0, 0]])\n",
    "    conv = slim.convolution(inp, n_hidden, filter_size, data_format=\"NHWC\", padding=\"VALID\", activation_fn=None)\n",
    "    conv = tf.squeeze(conv, 2)\n",
    "    return conv\n",
    "\n",
    "def decoder_block(inp, n_hidden, filter_size):\n",
    "    inp = tf.expand_dims(inp, 2)\n",
    "    inp = tf.pad(inp, [[0, 0], [filter_size[0]-1, 0], [0, 0], [0, 0]])\n",
    "    conv = slim.convolution(inp, n_hidden, filter_size, data_format=\"NHWC\", padding=\"VALID\", activation_fn=None)\n",
    "    conv = tf.squeeze(conv, 2)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glu(x):\n",
    "    return tf.multiply(x[:, :, :tf.shape(x)[2]//2], tf.sigmoid(x[:, :, tf.shape(x)[2]//2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def layer(inp, conv_block, kernel_width, n_hidden, residual=None):\n",
    "    z = conv_block(inp, n_hidden, (kernel_width, 1))\n",
    "    return glu(z) + (residual if residual is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoder(inp, n_layers, device):\n",
    "    with tf.variable_scope(\"encoder\", reuse=device > 0), tf.device(\"/gpu:%d\" % device):\n",
    "        inp = e = tf.nn.dropout(inp, dropout_keep_prob)\n",
    "        for i in range(n_layers):\n",
    "            z = layer(inp, encoder_block, 3, n_hidden * 2, inp)\n",
    "            z = tf.nn.dropout(z, dropout_keep_prob)\n",
    "            inp = z\n",
    "        return z, z + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decoder(inp, zu, ze, n_layers, device):\n",
    "    with tf.variable_scope(\"decoder\", reuse=device > 0), tf.device(\"/gpu:%d\" % device):\n",
    "        inp = g = tf.nn.dropout(inp, dropout_keep_prob)\n",
    "        for i in range(n_layers):\n",
    "            attn_res = h = layer(inp, decoder_block, 3, n_hidden * 2, residual=tf.zeros_like(inp))\n",
    "            C = []\n",
    "            for j in range(n_attn_heads):\n",
    "                h_ = slim.linear(h, n_hidden//n_attn_heads)\n",
    "                g_ = slim.linear(g, n_hidden//n_attn_heads)\n",
    "                zu_ = slim.linear(zu, n_hidden//n_attn_heads)\n",
    "                ze_ = slim.linear(ze, n_hidden//n_attn_heads)\n",
    "                \n",
    "                d = slim.linear(h_, n_hidden//n_attn_heads) + g_\n",
    "                dz = tf.matmul(d, tf.transpose(zu_, [0, 2, 1]))\n",
    "                a = tf.nn.softmax(dz)\n",
    "                c_ = tf.matmul(a, ze_)\n",
    "                C.append(c_)\n",
    "            c = tf.concat(C, 2)\n",
    "            h = slim.linear(attn_res + c, n_hidden)\n",
    "            h = tf.nn.dropout(h, dropout_keep_prob)\n",
    "            inp = h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_loss(hg, jp_batch, device):\n",
    "    with tf.variable_scope(\"logits\", reuse=device > 0), tf.device(\"/gpu:%d\" % device):\n",
    "        logits = slim.fully_connected(hg, jp_vocab_size) ## ?\n",
    "        logits = logits[:, :-1]\n",
    "        pred = tf.nn.softmax(logits)\n",
    "        logits_shape = tf.shape(logits)\n",
    "        logits = tf.reshape(logits, [logits_shape[0] * logits_shape[1], jp_vocab_size])\n",
    "        labels = jp_batch[:, 1:]\n",
    "        labels = tf.reshape(labels, [-1,])\n",
    "        loss_mask = labels > 0\n",
    "        logits = tf.boolean_mask(logits, loss_mask)\n",
    "        labels = tf.boolean_mask(labels, loss_mask)\n",
    "        \n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        tf.summary.scalar('softmax_loss', loss);\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_optimizer(loss, params, global_step, device):\n",
    "    with tf.variable_scope(\"optimizer_%d\" % device), tf.device(\"/gpu:%d\" % device):\n",
    "        opt = tf.train.AdamOptimizer(1e-4)\n",
    "        grads = opt.compute_gradients(loss, params)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_gpus = 1\n",
    "n_layers = 4\n",
    "filenames = glob.glob(\"../data/translation_id.tsv\")\n",
    "losses = []\n",
    "for device in range(n_gpus):    \n",
    "    random.shuffle(filenames)\n",
    "    en_batch, jp_batch = data_feed(filenames, batch_size=64)\n",
    "    en_emb, jp_emb = init_embedding(en_batch, jp_batch, reuse=device > 0)\n",
    "    zu, ze = encoder(en_emb, n_layers, device)\n",
    "    hg = decoder(jp_emb, zu, ze, n_layers, device)\n",
    "    loss = init_loss(hg, jp_batch, device)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "params = tf.trainable_variables()\n",
    "global_step = tf.get_variable(\"global_step\", shape=[], dtype=tf.int64, initializer=tf.constant_initializer(0), trainable=False)\n",
    "train_ops = []\n",
    "for device in range(n_gpus):\n",
    "    train_op = init_optimizer(losses[device], params, global_step, device)\n",
    "    train_ops.append(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_every = 100\n",
    "checkpoint_every = 1000\n",
    "\n",
    "def train_loop(sess, coord, saver, summary, summary_writer, train_op, global_step, device, run_event):\n",
    "    try:\n",
    "        while not coord.should_stop() and run_event.is_set():\n",
    "            _, step, s = sess.run([train_op, global_step, summary])\n",
    "            summary_writer.add_summary(s, step)\n",
    "            if step % log_every == 0:\n",
    "                summary_writer.flush()\n",
    "            if step % checkpoint_every == 0:\n",
    "                saver.save(sess, checkpoint_dir + \"/model.ckpt\")\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"device %d id done!\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fresh\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import threading\n",
    "\n",
    "\n",
    "checkpoint_dir = \"../checkpoints/tatoeba_v3\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "saver = tf.train.Saver(params + [global_step])\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "with tf.Session(config=config) as sess:\n",
    "    summary = tf.summary.merge_all()\n",
    "    summary_writer = tf.summary.FileWriter(checkpoint_dir)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if glob.glob(checkpoint_dir + \"/model.ckpt*\"):\n",
    "        saver.restore(sess, checkpoint_dir + \"/model.ckpt\")\n",
    "        print(\"loaded checkpoint\")\n",
    "\n",
    "    else:\n",
    "        print(\"start fresh\")\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    try:\n",
    "        run_event = threading.Event()\n",
    "        run_event.set()\n",
    "        train_threads = []\n",
    "        for device in range(n_gpus):\n",
    "            t = threading.Thread(target=train_loop, args=[sess,\n",
    "                                                         coord,\n",
    "                                                         saver,\n",
    "                                                         summary,\n",
    "                                                         summary_writer,\n",
    "                                                         train_ops[device],\n",
    "                                                         global_step,\n",
    "                                                         device,\n",
    "                                                         run_event])\n",
    "            t.start()\n",
    "            train_threads.append(t)\n",
    "        for t in train_threads:\n",
    "            t.join()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"stopped\")\n",
    "        run_event.clear()\n",
    "        for t in train_threads:\n",
    "            t.join()\n",
    "        print(\"stopped all threads\")\n",
    "    finally:\n",
    "        # When done, ask the threads to stop.\n",
    "        summary_writer.flush()\n",
    "        saver.save(sess, checkpoint_dir + \"/model.ckpt\")\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
